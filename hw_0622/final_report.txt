프로세서마이크로아키텍처 기말고사 리포트

- Caches

Physical address는 프로세서가 접근 가능한 address 범위를, virtual address는 application program이 보는
address 범위를 가진다. 이와 같은 분리를 통해 프로그램들은 physical memory 크기에 상관없이 수행가능하고
multitasking 시에 다른 프로그램으로부터 메모리 분리가 가능하다.
physical address로부터 virtual address로의 변환은 page 단위로(4~8KB) 이루어지며, mapping 정보는 page table에 저장된다.
Address translation 성능은 전체 성능에 크게 영향을 미치므로, translation lookaside buffer (TLB)에 page table 정보가 caching된다.

Cache는 크게 tag array와 data array로 나뉜다. Data array에는 data 혹은 instruction이 저장되고, tag array는 data array entry의 
주소 비교를 위해 사용된다. 각 array는 여러 set을 가지고 각 set은 block의 집합으로 이루어진다. 한 set에 포함된 block의 갯수를 
해당 cache의 degree of associativity로 일컬으며 associativity N의 cache는 N-way associative cache라고도 부른다. 
Associativity degree가 1인 cache는 direct mapped cache라고 한다.
Cache는 주어진 memory address를 tag, index, offset의 세 부분으로 나누어, index 값 i에 따라 얻어진 tag array의 
i번째 tag array set, N개의 tag array 값이 memory address의 tag part와 비교되어 cache hit 여부를 알아낸다. Cache hit의 상황에서
i번째 data array set에서부터, hit이 일어난 set의 index를 이용한 multiplexing이 이루어지고, 마지막으로 memory address의 offset 값에
따른 align이 이어진다.  

구현상의 variation으로는 tag array와의 tag 비교와 더불어 data array와의 접근이 동시에 일어나는 구조 혹은 tag array와의 tag 비교
이후에 data array에의 접근이 이루어지는 구조가 존재한다. Tag/data array에의 동시 접근은 serialized 접근에 비해 빠른 속도를 가지나,
serialized 구조의 경우 data path에의 way multiplexor가 필요하지 않게 되고, tag array에의 critical path가 짧아지는 특성을 가진다.
이는 더 적은 power consumption과 higher frequency를 가능케 한다. 이러한 구조적 특성에 따라, memory latency가 비교적 잘 숨겨지면서
data cache가 processor frequency에 제일 주요한 영향을 끼치는 경우에는 순차적 구조 방식이 reasonable한 선택이 된다. Memory latency
최소화를 우선시할 경우에는 동시 접근 구조를 채택해야 할 것이다.
Associativity의 선택 또한 성능에 영향을 미친다. Direct mapped cache는 access 속도가 제일 빠르지만 conflict miss에 취약하다. 반대로, associativity가 높아지면 conflict miss는 줄지만 way multiplexor가 커짐에 따라 속도가 느려진다.

Memory request가 L1 cache에서 miss될 경우, 해당 request는 다음 level의 memory hierarchy로 forward된다. 
이때, blocking cache system의 경우 해당하는 outstanding miss가 끝날 때까지 프로세서를 stall시킨다. 이는 간단히 구현 가능하나
cache miss 시에 성능 저하를 가져오게 된다. 또다른 구현 방법으로는 cache miss가 진행되는 동안 instruction 수행을
계속하는 방식이 있다. 이때 해당 miss에 종속되지 않는 instruction은 수행을 계속하도록 하고 dependent한 instruction에 한해
blocking이 이루어진다. 이와 같은 방식을 nonblocking cache 혹은 lockup-free cache라고 한다.
처음 고안된 lockup-free 방식은 Implicitly Addressed MSHR이다. 해당 방식에서 MSHR은 primary miss를 저장하고, 각 MSHR은 또한
word별 miss information들을 저장한다. Secondary miss가 발생했을 경우 본인이 속하는 primary miss MSHR의 word entry 중 하나에 정보를
저장하게 된다. 이와 같은 방식은 매 word 별 하나의 secondary miss밖에 기록하지 못한다는 단점을 가져, 이를 보완하기 위한 방식으로
Explicitly Addressed MSHR이 고안되었다. 이는 각 MSHR field에 block offset information 정보를 추가함으로써, word별로 positional하게
secondary miss 정보가 저장되어야 하는 필요성을 없앴다. 또다른 구현 방식으로는, 사용되지 않고 있는 cache block을 MSHR storage로
이용하는 아이디어의 In-Cache MSHR이 존재한다. In-Cache MSHR에서 tag array는 transient bit를 추가적으로 가지게 되고, 이를 통해
transient mode에서 tag array는 fetch되어 올 block의 address를, data array는 MSHR information을 가지게 된다.

High execution bandwith를 위해 많은 프로세서들이 매 cycle 2 memory instruction들을 issue할 수 있음에 따라, dual-ported cache
의 필요성 또한 대두되었다. Dual-port cache의 구현 방법으로는 우선 true dual-ported cache, array replication,
virtual multiporting 그리고 multibanking 등 다양한 방법이 존재한다.
True multiported cache에서는 모든 control/data path가 replicate된다. 이때 tag/data array는 replicate되지 않는다.
Array 또한 replicate하는 방식 또한 존재하고, 이때 두 replica 사이의 synchronization이 성능상 문제로 자리잡는다.
IBM Power2와 Alpha 21264에는 virtual multiporting이 구현되었다. Alpha 21264에서는 data array를 double-pump하는 방식으로, 즉
cycle의 첫 half와 두 번째 half에 서로 다른 load를 진행함에 따라 2개의 read port를 가진 것과 같은 효과를 낸다. 이는
clock frequency가 작아짐에 따라 적용하기 힘든 구조가 되었다.
Cache를 여러 개의 bank로 나누는 방식의 multibanking 구조 또한 존재한다. 이때 동일한 bank에의 접근은 bank conflict을 일으키며,
서로 다른 bank에의 접근은 한 cycle 내에서 이루어 질 수 있다. 본 구조가 현재 많은 프로세서 구조에서 채택하고 있는 방식이다.

Instruction cache의 경우 program instruction이 가지는 여러 특성 탓에 data cache와는 다른 구조적 선택이 가능하다.
프로그램 instruction은 보통 메인 메모리 내에 consecutive하게 저장되므로, single port cache로도 한 block 내에서 여러 instruction을 issue하는 것이 가능하다. 또한 대부분의 instruction들은 프로그램 순서에 따라 본인 이전의 instruction에 dependent하기 때문에
lockup-free instruction cache를 쓰는 것에서 성능상 이점을 얻기가 힘들다.

- The Instruction Fetch Unit

Instruction fetch unit은 instruction을 feed하는 역할의 unit으로, instruction cache 및 fetch address 계산 logic으로 이루어져 있다.
Instruction cache 구현 방식 중에는 instruction의 dynamic order를 저장함으로써 fetch 시의 effective bandwidth를 늘리는 방식의 trace cache가 존재한다.
매 cycle instruction을 fetch하는 데에 있어 큰 장애물 중 하나는 branch instruction으로, 이는 실행 완료 전까지 올바른 fetch address를
알지 못하게 한다. 이를 타개하기 위해 사용하는 방법 중 하나는 branch prediction으로, 이는 branch가 taken일지 아닐지를 예측한다.
추가로, branch target buffer (BTB)를 사용하여 branch의 targeet address 또한 예측한다.

Branch의 결과 예측에는, 해당 branch가 taken일지 아닐지에 대한 예측과 더불어 해당 branch의 target address에 대한 예측이 필요하다.
대부분의 branch instruction은 target address를 PC relative하게 정의하므로, target address 계산은 해당 instruction이 fetch된 이후 가능하다.
이러한 bubble cycle을 없애기 위해서는 target address 예측이 필요하고, 이는 보통 fetch address를 index로 하는 table, BTB를 가짐으로써 이루어진다.
Branch execution 이후에 target address가 해당 table에 저장되어, 다음 동일 branch 수행 시에 사용된다.
Subroutine 상에서의 target address는 Return Address Stack이라는 별도의 LIFO 구조에 저장된다. 프로세서가 subroutine call을 fetch할 때마다
다음 instruction의 address가 해당 stack에 push되고, return instruction을 만날 경우 RAS의 top entry가 pop되어 예측된 target address로써 사용된다.

Branch가 taken일지 아닐지에 관한 prediction인 conditional branch prediction은 static prediction과 dynamic prediction으로 나뉜다.
Static prediction은 profiling 정보를 사용하는 경우 각 branch의 most frequent outcome을 사용하거나, 단순히 loop closing branch를 taken으로, 그 외에는
not taken으로 예측하는 방식 등으로 prediction을 할 수 있다.
Dynamic prediction은 프로그램의 수행 정보를 바탕으로 branch의 결과를 예측하는 방식을 일컫는다. 단순하게는 2 bit의 entry들로 이루어진 table을 만들어
PC 값으로 table index를 계산하고 2 bit entry로는 finite-state machine을 구축하여 주어진 주소값에서 예상되는 다음 결과값을 계산하도록 할 수 있다. 
이러한 방식의 predictor는 local information만을 사용하는 local branch predictor이고, 이와 달리 global history를 사용하여 prediction을 하는
global branch prediction 및 local, global 두 방식을 같이 사용하여 예측 성능을 높이는 hybrid 방식 또한 존재한다. 

- Decode

Decode stage에서는 instruction의 semantic을 파악하여 어떤 execution을 수행해야 할 것인가에 대한 정보를 얻을 수 있다. Decode unit은 주어지는 byte stream
을 valid instruction으로 나누는 것에서부터 시작하고, 해당 작업은 ISA에 따라 complexity가 크게 바뀌게 된다.

대부분의 RISC 프로세서는 고정된 길이의 instruction 길이를 가지는데, 이로써 byte stream으로부터 instruction을 추출하는 일은 RISC 상에서는 간단한 작업이 된다.
이와 반대로, x86은 variable-length의 CISC instruction set이다. x86 instruction은 최대 4 bytes 길이의 prefix(optional), 1 ~ 3bytes의 필수 opcode, 
addressing specifier(optional)를 가진다. 추가로 displacement(~ 4bytes), intermediate field(~ 4bytes) 더해지기도 한다.
이와 같은 instruction을 decode할 시에는 instruction length를 파악하는 것이 우선된다. 또한 operand 추출에도 다양한 가능성이 고려되어야 한다.
이처럼 복잡한 구조 탓에 최신 x86 프로세서에서 decoding은 여러 cycle을 소모하게 된다.
최신의 out-of-order x86 프로세서는 x86 instruction을 dynamically translate하여 내부적으로 RISC-like format으로 변환하여 사용하고 있다.
Intel에서는 이러한 내부 instruction을 micro-operation으로 칭하고 있다. 이러한 변환은 instruction을 parallel하게 수행할 수 있게 한다.
Intel Nehalem 구조에서는 decoding phase가 instruction length decoder phase와 dynamic translation to micro-ops phase로 나뉨을 확인할 수 있다.
이렇게 phase를 분리함으로써 length decoder phase 내부의 bubble을 숨기는 한편 두 phase의 동시 수행을 가능하게 하였다.

- Allocation

Allocation phase에서는 register renaming과 instruction dispatch가 이루어진다.
Register renaming을 통해서는 in-flight instruction의 name dependency를 resolve할 수 있다. 여기에는 register 재사용에 따른 false dependency를 포함한다.
Instruction dispatch는 이후 execution을 위한 resource allocation을 일컫는다.
Register renaming의 구현 방식은 크게 renaming through the reorder buffer, renaming through a rename buffer 그리고 merged register file의 세 가지로 나뉜다.

Renaming through the reorder buffer는 register value를 reorder buffer(ROB)와 architectural register file에 저장하는 방식을 일컫는다.
ROB에는 commit되지 않은 instruction 결과가 기록되고 architectural register file에는 마지막으로 commit된 register 결과가 작성된다.
또한 rename table을 통해 매 architectural register의 값이 ROB에 저장되어 있는지 architectural register file에 저장되어 있는지를 확인할 수 있다.
Instruction이 수행되고 나면 해당 결과는 ROB에 저장되고, commit 시에 architectural register file로 복사된다. 
Renaming through a rename buffer 방식은, 많은 수의 instruction이 register result를 만들어 내지 않는다는 점에서 착안하여, instruction의 result 저장을 위한
별도의 structure(rename 를 가진다. 이를 통해 output result를 가지는 instruction에만 storage가 allocate된다.

Merged Register File은 speculative, commited value 모두를 하나의 physical register file에 저장하는 방식이다. 각 register는 free 혹은 allocated 상태로 존재하며
free register는 free list를 통해 관리된다. Register 값으로는 commited value, speculative value 혹은 none(allocate된 이후 result가 작성되기 이전)의 값이 
저장될 수 있다. 추가로 register map table이 존재하여 architectural register에 해당하는 physical register id가 저장된다.
Instruction renaming 시에, rename map을 통해 operand에의 접근이 이루어지며, 해당 instruction이 register 결과값을 가질 시에는 free physical register가 
allocate되어 결과값이 저장되고 rename map table 또한 업데이트된다. Physical register release는 해당 값이 더 이상 사용되지 않을 때 가능하다. 즉, 
동일한 architectural destination register를 가지는 instruction의 commit 순간에, 해당 architectural register에의 mapping을 가지고 있던 physical register의 
release가 이루어진다.

Reorder buffer와 rename buffer의 경우 merged register file에서와 같은 free list 관리가 필요없다는 점이 장점으로 꼽힌다. 
Merged register file의 경우, ROB 방식의 경우 register 값이 처음에는 ROB, 다음에는 architectural register file에 작성되는 것과 달리, 
register 값이 한번 작성되고 이후에는 수정되지 않는다는 장점을 가진다. 또한 ROB의 경우 operand 값의 위치가 ROB, architectural register file 두 곳 중 하나에서
올 수 있는 것에 반해 merged register file에서는 operand 값을 언제나 동일한 location으로부터 읽을 수 있다는 장점이 있다. 

Register renaming scheme과 함께 고려되어야 하는 부분은 "언제 register값을 읽느냐"이다. 여기에는 read before issue, read afer issue의 두 가지 방식이 존재한다.
Read before issue의 경우 instruction이 issue queue로 dispatch되기 전에 register file로부터 값을 읽는다. 이때 존재하지 않는 operand의 경우 unavailable bit이 mark되고
bypass network를 통해 operand를 읽어들인다. 이 방식은 register file에 적은 port만을 필요로 하는 장점을 가지나, issue queue에 operand value까지 같이 저장해야 하기 때문에
storage 측면의 cost가 추가된다. 또한, operand 값을 register file에서 읽어 issue queue에 적고, issue queue에서 또 값을 읽어 execution unit으로 보내는 식의 data
flow로 energy 낭비를 일으킨다. Read after issue의 경우 issue queue에는 operand 값 대신 register id만이 저장되어 실질적으로 값을 읽는 시점은 instruction이 execution
unit으로 issue된 이후이다. 이는 register file에 추가적인 port를 필요로 하지만 중복된 operand 읽고 쓰기를 줄일 수 있다.

Merged register file은 read before issue, read after issue의 두 가지 방식 모두에 적합한 renaming scheme이다. 그러나 reorder buffer나 rename buffer 방식의 
경우 fead after issue에 적용되기 힘든 성질을 가진다. 이는 reorder/rename buffer 방식에서 register 값이 reorder/buffer로부터 architectural register file로 
옮겨가기 때문이다. 한번 register id가 issue queue에 저장된 이후에 register 값이 옮겨지면 해당 id가 invalid해질 수 있기 때문이다.

- The Issue Stage

Issue stage에서는 instruction이 execution unit으로 issue된다. Issue 방식에는 in order, out of order의 두 가지 방식이 존재한다. 또한
out of order issuing에는 많은 implementational choice가 존재한다.

In-order issue란 instruction이 fetch된 순서대로 execution unit에 issue하는 것을 말한다.
이에 반해 instruction-level parallelism을 확보하기 위한 방안으로 out-of-order issue logic이 고안되었다.
Issuing scenario는 source operand가 read before issue 방식인지 read after issue 방식인지에 따라 달라지는 양상을 보인다.

Source operand가 read before issue 방식으로 접근되는 경우, issue queue에는 instruction issue를 위한 정보 및 source operand 값의 저장이 필요하다.
또한 issue 내부적으로 issue queue allocation, instruction wakeup, instruction selection 및 issue queue reclamation의 과정을 거친다.
Issue queue allocation 시에 instruction은 allocation stage를 거쳐 issue queue로 저장된다. Instruction wakeup는 source operand의 값이 나왔음을 알리는 과정이다.
Instruction selection에서는 모든 source operand가 ready된 instruction 중 execute될 instruction이 결정되고, Entry reclamation에서는 issue queue entry가 reclaim된다.

Source operand가 read after issue 방식으로 접근될 때에는, issue queue에 source operand 값의 저장이 필요없어진다.
즉, wakeup signal을 통해 operand 값을 forward할 필요가 없어진다. 또한 renaming stage와 issue queue allocation 사이에 필요한 stage도 줄게 된다.
그 대신 wakeup과 execution 사이에 source operand를 읽기 위한 cycle이 추가된다.

Memory disambiguation policy란 memory dependency를 resolve하기 위한 전략을 일컫는다. 전체 instruction의 30% 정도가 memory operation인 점에 따라, 
memory disambiguation policy는 프로세서의 complexity 및 성능에 지대한 영향을 미친다.

이전 memory operation과의 dependency가 전부 해결되기 전까지 memory operation을 수행하지 않는 방식을 
nonspeculative memory disambiguation 방식이라 한다. 이에는 total ordering, load ordering with store ordering, partial ordering
의 세 종류가 있다.
total ordering에서는 모든 memory access가 순서대로 실행된다.
partial ordering에서는 모든 store만 순서대로 실행되고, load는 이전 store가 address를 계산하였다는 조건 하에서 out-or-order로 수행된다.
load ordering and store ordering에서는 load와 store가 out of order로 수행되나, 모든 load 자체는 순서대로, 그리고 모든 stroe 또한 순서대로 수행된다.

Load Ordering and Store Ordering의 구현 예시로는 AMD K8 프로세서가 있다.
해당 프로세서는 load와 store를 위한 두 separate pipeline을 가진다.
disambiguation stage에서 load는 store buffer에 저장된 store 중 본인보다 old하며 본인과 동일한
address를 참고하는지 확인하여, 만일 old store를 만난다면 load pipeline은 stall된다.

Partial ordering의 구현 예시로는 MIPS R10000이 있다.
MIPS R10000은 하기의 두 matrix 구조를 manage한다.
indetermination matrix: 16 x 16 lower triangular matrix로, 매 행과 열이 load/store queue entry를 의미한다.
                        memory operation은 rename stage에서 해당하는 entry index의 열을 1로 세팅하고, address 계산 이후에 0으로 리셋된다. 
                        memory operation은 indetermination matrix의 해당 entry index 행을 확인하여 1이 있으면 issue되지 못한다.
dependency matrix: 16 x 16 lower triangular matrix로, 매 행과 열이 load/store queue entry를 의미한다.
                   이전 store에 dependent한 load가 있을 경우, load entry index의 depdendenty matrix 행에서, 
                   각 column 중 dependency가 존재하는 store entry의 값을 1로 세팅한다. 
                   store는 memory update 이후에 해당 entry index의 열을 0으로 리셋하고,
                   load은  해당 entry index의 행에 1이 있을 경우 issue되지 못한다.
상기의 두 matrix 구조를 통해 MIPS R10000은 partial ordering, 즉 동일 address를 refer하는 store에 dependent한 상태로 load를 수행하는 방식을 구현한다. 

Speculative memory disambiguation이란 주어진 memory operation이 다른 in-flight memory operation과의 memory dependency를 가지는지
예측하는 방식으로 실행되는 것을 일컫는다. 즉, in-flight store과의 dependency가 없다고 예상되어질 경우 이전 store이 address 계산을 끝날 때까지 load operation이 기다리지 않는다. 이는 성능의 향상을 가져올 수 있으나, 또한 misprediction 시의 recovery 방식 또한 필요로 한다.

Speculative memory disambiguation 방식을 사용하는 예로는 Alpha 21264가 있다. Alpha 21264는
wait table을 관리하는데, 이는 어떤 store에 dependent한 load를 만날 때에, 해당 load의 virtual address를 의미하는 
table 내의 entry 값을 1로 세팅한다. fetch unit은 이 table을 읽어, 만일 1이 설정된 경우 speculative issue를 실행하지 않는다.
또한 해당 table은 16,384 cycle마다 리셋되어 table 값이 1로 수렴하는 것을 막는다.

- Execute

Execution stage에서는 instruction의 정보 및 operand를 통한 실질적인 computation이 이루어진다. 
프로세서가 구현하는 각각의 operation마다 서로 다른 complexity를 가지기 때문에, 현시대의 프로세서는 execute stage를 여러 pipelined stage로 구현하고 있다.

Integer Arithmetic and Logical Unit는 integer addition, subtraction과 같은 integer arithmetic operation과 더불어, AND, OR, NOT, XOR과 같은
logical operation 기능을 제공한다.
Multiplication과 division은 높은 complexity와 필요 면적의 이유로 ALU와는 별도로 구현된다. 일부 프로세서에서는
FPU를 통한 integer multiplication, division 기능이 제공된다. 이를 위하여는 integer source가 floating-point로 변환된 후,
최종 결과가 다시 integer로 변환되는 방식을 차용한다. 이는 high latency를 낳지만, 보통 integer multiplication과 division이 많이 
사용되지 않는다는 점으로 미루어, 파워 및 면적 면에서의 이득이 크다고 생각되어지는 경우가 있다.
Branch unit은 branch, jump, function call, return 등의 control-flow instruction 수행 및 다음 instruction address(PC) 계산을 행하는 유닛이다. 
Control-flow instruction은, 프로그램의 수행 결과에 flow가 변하는 (branch) conditional flow와 늘 동일한 flow를 가지는 (jump)
unconditional flow로 나뉠 수 있다.
Floating-Point Unit은 floating-point value를 RF 혹은 memory 입력으로 받아 floating-point 결과를 만들어 내는 유닛이다. 
Addition, subtraction, multiplication의 operation을 수행하며, 구현 방식에 따라, division, square root나 exponential 등의 complex operation 기능이 같이 제공되는 경우도 있다.
FPU는 굉장이 복잡하여 보통 integer unit보다 몇 배는 크다.
SIMD unit은 동일한 operation을 주어진 입력 group에 동시에 수행하는 유닛을 일컫는다.
유명한 SIMD instruction set으로는 x86의 SSE 등이 있다.
Result bypassing은 결과값이 commit stage를 통해 state에 업데이트되기 전에 값을 사용함으로써 cycle을 절약하고 성능을 높이는 방식이다.

- The Commit Stage

프로세서는 외부적으로 instruction을 sequential하게 수행한다. 그러나 내부적으로는 out of order 수행을 통해 
sequential order와는 다른 state를 만들어 낼 수 있다. 이러한 경우에 sequential order를 emulate하기 위한 방법으로는 
commit stage를 pipeline의 말단에 두고 프로세서가 architectural state와 speculative state의 두 state에서 기능하게 하는 방법이 있다.
Architectural state는 instruction이 commit된 경우에만 업데이트되어 프로세서가 sequential하게 수행되는 것처럼 보이게 한다.
이와 달리 speculative state에는 architectural state에 더해 in-flight modification 또한 포함된다.

P6과 같은 프로세서의 경우에는 reorder buffer 및 retire register file(RRF)를 통해 speculative state와 architectural state를 구현한다.
Instruction의 수행 결과는 ROB에 저장되고 commit되는 순간에 해당 값은 RRF로 옮겨진다. 상기 본 것과 같이, 이와 같은 ROB with RRF 방식은
read after issue 방식의 source operand 접근 방식에는 불리하다.

MIPS R10000, Alpha 21264나 Intel Pentium 4의 경우에는 architectural state와 speculative state가 동일한 register file에 저장되는
merged register file을 구현하고 있다. 이때, RF내 value 값은 (ROB 구현 때와 같이) 위치를 이동하지 않으므로, read-after-issue
시에도 renaming table과 in-flight instruction에 위치 변경에 대한 notify를 필요로 하지 않는다.
Resource reclamation 시에도, ROB entry는 instruction이 commit된 직후 reclaim되는 반면 merged RF는 해당 entry 값이 이후에도
사용되는지 확인 후에 reclaim해야 한다. 즉, instruction A에 의해 할당받아진 register는 A보다 이후에 나타나는 instruction B가 
A와 동일한 logical registser에 값을 적을 때에야 reclaim이 가능해진다.

speculative state는 branch misprediction이나 younger instruction에서의 exception 발생 시에 수정사항을 undo해한다.
이는 ROB 방식이냐 merged RF 방식이냐에 따라 구현 방식이 달라진다.

Branch misprediction 시에 speculative state에는 잘못된 path로의 fetch, rename 및 execute가 이루어진 invalid state가 저장된다.
즉 branch misprediction이 발견될 경우 speculative state 및 PC는 wrong path 이전의 상태로 되돌아가야 한다.
Recovery 과정은 크게 front-end recovery와 back-end recovery의 두 부분으로 나뉜다. Front-end recovery는 잘못 fetch된 instruction의
flushing, branch predictor history의 restoring 및 PC 업데이트를 일컫는다. Back-end recovery는 memory order buffer, issue queue,
reorder buffer 등의 buffer에 잘못 포함된 instruction들을 제거하는 것을 말한다. Renaming table 또한 restore되어야 하고,
잘못 allocation된 resource 또한 reclaim되어야 한다. Front-end recovery는 Back-end recovery보다 빨리 끝나기 때문에 
correct path에서의 fetch부터 allocation 이전까지와 back-end recovery는 overlap될 수 있다.

Retire register file을 가지는 ROB 방식의 구조에서는 mispredicted branch 자신 및 그 이전의 instruction들이 모두 
commit되기 전에 recovery가 수행되지 않는다.
Merged register file 방식에서는, renaming table의 수정 log가 저장된다. Branch misprediction이 발생할 경우,
해당 log를 역산함에 따라 올바른 state를 찾을 수 있다. Log 역산의 속도를 빠르게 하기 위해 MIPS R10000과 Alpha 21264는
주기적으로 checkpoint를 만들어 log 역산 거리를 줄인다. 

Exception recovery는 commit 시에 이루어진다. 이는 해당 exception이 wrong path에의 결과가 아님을 확언하고,
exceptional instruction 이전의 instruction들이 모두 수행 완료되어야 하기 때문이다. Exception recovery 시에는
in-flight instruction들이 전부 flush되고, speculative state가 recover되며, instruction fetch는 exception handler
부터 재시작한다.